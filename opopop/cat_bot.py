import os
import cv2
import numpy as np
import torch
import torch.nn.functional as F
from torchvision import models, transforms
from PIL import Image, ImageDraw, ImageFont
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    ConversationHandler,
    filters
)

# –°–æ—Å—Ç–æ—è–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
MENU, PROCESS_IMAGE = range(2)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
TOKEN = "7768210415:AAEQh6__p2PIRwo4R7Vwy9BCaudmfm0lGYw"
TEXT_PADDING_TOP = 30
TEMP_DIR = "../temp_files"

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
os.makedirs(TEMP_DIR, exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# –ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ—à–µ–∫
detection_model = models.detection.maskrcnn_resnet50_fpn(pretrained=True).to(device)
detection_model.eval()

# –ú–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã
heatmap_model = models.mobilenet_v2(pretrained=True).to(device)
heatmap_model.eval()

# –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –º–µ–Ω—é
menu_keyboard = ReplyKeyboardMarkup(
    [["–ù–∞–π—Ç–∏ –∫–æ—à–∫—É", "–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞"]],
    resize_keyboard=True,
    one_time_keyboard=True
)


def get_temp_path(filename):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É"""
    return os.path.join(TEMP_DIR, filename)


async def cleanup_temp_files():
    """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    for filename in os.listdir(TEMP_DIR):
        file_path = os.path.join(TEMP_DIR, filename)
        try:
            if os.path.isfile(file_path):
                os.unlink(file_path)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await cleanup_temp_files()
    await update.message.reply_text(
        "üê± –ü—Ä–∏–≤–µ—Ç! –Ø CatFinderBot!\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=menu_keyboard
    )
    return MENU


async def menu_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –≤ –º–µ–Ω—é"""
    choice = update.message.text
    context.user_data["choice"] = choice
    await update.message.reply_text(
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Ñ–æ—Ç–æ —Å –∫–æ—à–∫–æ–π",
        reply_markup=None
    )
    return PROCESS_IMAGE


async def process_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_choice = context.user_data.get("choice", "")
    photo_file = await update.message.photo[-1].get_file()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    temp_input_path = get_temp_path("input.jpg")
    await photo_file.download_to_drive(temp_input_path)

    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ—à–∫–∏
        has_cat = await check_for_cat(temp_input_path)

        if not has_cat:
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å –∫–æ—à–∫—É")
            return MENU

        # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–æ—à–∫–∞ –Ω–∞–π–¥–µ–Ω–∞ - –≤—ã–ø–æ–ª–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
        if user_choice == "–ù–∞–π—Ç–∏ –∫–æ—à–∫—É":
            result_path = get_temp_path("result.jpg")
            await find_cat(temp_input_path, result_path)
            await update.message.reply_photo(photo=open(result_path, "rb"))
        elif user_choice == "–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞":
            result_path = get_temp_path("heatmap.jpg")
            await generate_heatmap(temp_input_path, result_path)
            await update.message.reply_photo(photo=open(result_path, "rb"))

    except Exception as e:
        await update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}")
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        if os.path.exists(temp_input_path):
            os.remove(temp_input_path)
        if 'result_path' in locals() and os.path.exists(result_path):
            os.remove(result_path)

    await update.message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=menu_keyboard)
    return MENU


async def check_for_cat(image_path):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ—à–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
    image = Image.open(image_path).convert("RGB")
    transform = transforms.Compose([transforms.ToTensor()])
    image_tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        prediction = detection_model(image_tensor)

    masks = prediction[0]['masks'] > 0.5
    labels = prediction[0]['labels']
    cat_masks = masks[labels == 17]  # 17 - –∫–ª–∞—Å—Å "–∫–æ—à–∫–∞" –≤ COCO

    return len(cat_masks) > 0


async def find_cat(input_path, output_path):
    """–û–±–≤–æ–¥–∏—Ç –∫–æ—à–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
    image = Image.open(input_path).convert("RGB")
    transform = transforms.Compose([transforms.ToTensor()])
    image_tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        prediction = detection_model(image_tensor)

    masks = prediction[0]['masks'] > 0.7
    labels = prediction[0]['labels']
    cat_masks = masks[labels == 17]

    mask = cat_masks[0].squeeze().cpu().numpy()
    mask = cv2.resize(mask.astype(np.uint8), image.size, interpolation=cv2.INTER_LINEAR)
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    image_np = np.array(image)
    result = cv2.drawContours(image_np.copy(), contours, -1, (0, 255, 0), 3)

    Image.fromarray(result).save(output_path)

async def generate_heatmap(input_path, output_path):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏"""

    # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    def preprocess_image(img):
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])
        return transform(img).unsqueeze(0).to(device)

    # 2. –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è Grad-CAM
    def get_gradcam(model, image_tensor):
        # –•—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π
        gradients = None
        activations = None

        # –•—É–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        def backward_hook(module, grad_input, grad_output):
            nonlocal gradients
            gradients = grad_output[0].detach()  # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º detach()

        # –•—É–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–π
        def forward_hook(module, input, output):
            nonlocal activations
            activations = output.detach()  # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º detach()

        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ö—É–∫–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–º —Å–ª–æ–µ
        target_layer = model.features[-1]
        forward_handle = target_layer.register_forward_hook(forward_hook)
        backward_handle = target_layer.register_full_backward_hook(backward_hook)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Ö—É–∫

        try:
            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            output = model(image_tensor)
            target_class = output.argmax().item()

            # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥
            model.zero_grad()
            output[0, target_class].backward()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π
            if gradients is None or activations is None:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏–ª–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏")

            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤
            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3], keepdim=True)

            # –í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–π
            weighted_activations = activations * pooled_gradients

            # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã
            heatmap = torch.mean(weighted_activations, dim=1, keepdim=True)
            heatmap = F.relu(heatmap)
            heatmap = heatmap / (torch.max(heatmap) + 1e-10)  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0

            return heatmap.squeeze().cpu().numpy()

        finally:
            # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ–º —Ö—É–∫–∏
            forward_handle.remove()
            backward_handle.remove()

    # 3. –ù–∞–ª–æ–∂–µ–Ω–∏–µ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    def overlay_heatmap(original_img, heatmap):
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL Image –≤ numpy array
        img_np = np.array(original_img)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É
        heatmap = cv2.resize(heatmap, (img_np.shape[1], img_np.shape[0]))
        heatmap = np.uint8(255 * (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap) + 1e-10))
        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

        # –ù–∞–ª–æ–∂–µ–Ω–∏–µ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        superimposed_img = cv2.addWeighted(img_np, 0.6, heatmap, 0.4, 0)
        return Image.fromarray(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))

    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        original_img = Image.open(input_path).convert("RGB")
        image_tensor = preprocess_image(original_img)

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É
        heatmap = get_gradcam(heatmap_model, image_tensor)

        # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_img = overlay_heatmap(original_img, heatmap)
        result_img.save(output_path)

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã: {str(e)}")
        raise

async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await cleanup_temp_files()
    await update.message.reply_text("–î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ", reply_markup=menu_keyboard)
    return MENU


def main():
    application = Application.builder().token(TOKEN).build()

    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("start", start)],
        states={
            MENU: [MessageHandler(filters.Regex("^(–ù–∞–π—Ç–∏ –∫–æ—à–∫—É|–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞)$"), menu_handler)],
            PROCESS_IMAGE: [MessageHandler(filters.PHOTO, process_image)]
        },
        fallbacks=[CommandHandler("cancel", cancel)]
    )

    application.add_handler(conv_handler)
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling()


if __name__ == "__main__":
    main()